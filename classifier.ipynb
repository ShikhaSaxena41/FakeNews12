{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataPrep\n",
    "import FeatureSelection\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_new = ['obama is running for president in 2016']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building classifier using naive bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipeline = Pipeline([\n",
    "        ('NBCV',FeatureSelection.countV),\n",
    "        ('nb_clf',MultinomialNB())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6072128577028616"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pipeline.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_nb = nb_pipeline.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_nb == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building classifier using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logR_pipeline = Pipeline([\n",
    "        ('LogRCV',FeatureSelection.countV),\n",
    "        ('LogR_clf',LogisticRegression())\n",
    "        ])ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6013328106624853"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logR_pipeline.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_LogR = logR_pipeline.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_LogR == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Linear SVM classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5723245785966288"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pipeline = Pipeline([\n",
    "        ('svmCV',FeatureSelection.countV),\n",
    "        ('svm_clf',svm.LinearSVC())\n",
    "        ])\n",
    "\n",
    "svm_pipeline.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_svm = svm_pipeline.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_svm == DataPrep.test_news['Label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVM Stochastic Gradient Descent on hinge loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6111328890631125"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_pipeline = Pipeline([\n",
    "        ('svm2CV',FeatureSelection.countV),\n",
    "        ('svm2_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3))\n",
    "        ])\n",
    "\n",
    "sgd_pipeline.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_sgd = sgd_pipeline.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_sgd == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6248529988239906"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = Pipeline([\n",
    "        ('rfCV',FeatureSelection.countV),\n",
    "        ('rf_clf',RandomForestClassifier(n_estimators=200,n_jobs=3))\n",
    "        ])\n",
    "    \n",
    "random_forest.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_rf = random_forest.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_rf == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined functon for K-Fold cross validatoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_confusion_matrix(classifier):\n",
    "    \n",
    "    k_fold = KFold(n_splits=5)\n",
    "    scores = []\n",
    "    confusion = np.array([[0,0],[0,0]])\n",
    "\n",
    "    for train_ind, test_ind in k_fold.split(DataPrep.train_news):\n",
    "        train_text = DataPrep.train_news.iloc[train_ind]['Statement'] \n",
    "        train_y = DataPrep.train_news.iloc[train_ind]['Label']\n",
    "    \n",
    "        test_text = DataPrep.train_news.iloc[test_ind]['Statement']\n",
    "        test_y = DataPrep.train_news.iloc[test_ind]['Label']\n",
    "        \n",
    "        classifier.fit(train_text,train_y)\n",
    "        predictions = classifier.predict(test_text)\n",
    "        \n",
    "        confusion += confusion_matrix(test_y,predictions)\n",
    "        score = f1_score(test_y,predictions)\n",
    "        scores.append(score)\n",
    "    \n",
    "    return (print('Total statements classified:', len(DataPrep.train_news)),\n",
    "    print('Score:', sum(scores)/len(scores)),\n",
    "    print('score length', len(scores)),\n",
    "    print('Confusion matrix:'),\n",
    "    print(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation for all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.66961153965076\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2118 2370]\n",
      " [1664 4088]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.6466692934443682\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2254 2234]\n",
      " [1936 3816]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.6104687487924283\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2260 2228]\n",
      " [2246 3506]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.6667995764719423\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2151 2337]\n",
      " [1706 4046]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.6995878055523893\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[1806 2682]\n",
      " [1214 4538]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_confusion_matrix(nb_pipeline)\n",
    "build_confusion_matrix(logR_pipeline)\n",
    "build_confusion_matrix(svm_pipeline)\n",
    "build_confusion_matrix(sgd_pipeline)\n",
    "build_confusion_matrix(random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5938847510780086"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nb_pipeline_ngram = Pipeline([\n",
    "        ('nb_tfidf',FeatureSelection.tfidf_ngram),\n",
    "        ('nb_clf',MultinomialNB())])\n",
    "\n",
    "nb_pipeline_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_nb_ngram = nb_pipeline_ngram.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_nb_ngram == DataPrep.test_news['Label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6193649549196394"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "logR_pipeline_ngram = Pipeline([\n",
    "        ('LogR_tfidf',FeatureSelection.tfidf_ngram),\n",
    "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
    "        ])\n",
    "\n",
    "logR_pipeline_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_LogR_ngram = logR_pipeline_ngram.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_LogR_ngram == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6170129361034888"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svm_pipeline_ngram = Pipeline([\n",
    "        ('svm_tfidf',FeatureSelection.tfidf_ngram),\n",
    "        ('svm_clf',svm.LinearSVC())\n",
    "        ])\n",
    "\n",
    "svm_pipeline_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_svm_ngram = svm_pipeline_ngram.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_svm_ngram == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sgd classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5417483339866719"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sgd_pipeline_ngram = Pipeline([\n",
    "         ('sgd_tfidf',FeatureSelection.tfidf_ngram),\n",
    "         ('sgd_clf',SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3))\n",
    "         ])\n",
    "\n",
    "sgd_pipeline_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_sgd_ngram = sgd_pipeline_ngram.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_sgd_ngram == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6099568796550372"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_ngram = Pipeline([\n",
    "        ('rf_tfidf',FeatureSelection.tfidf_ngram),\n",
    "        ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3))\n",
    "        ])\n",
    "    \n",
    "random_forest_ngram.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_rf_ngram = random_forest_ngram.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_rf_ngram == DataPrep.test_news['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation for all classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 10240\n",
      "Score: 0.7224053159841455\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[ 758 3730]\n",
      " [ 390 5362]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.7044355553757985\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[1580 2908]\n",
      " [1043 4709]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.6790920142902143\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2016 2472]\n",
      " [1524 4228]]\n",
      "Total statements classified: 10240\n",
      "Score: 0.7189849719606326\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[   5 4483]\n",
      " [   7 5745]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "build_confusion_matrix(nb_pipeline_ngram)\n",
    "build_confusion_matrix(logR_pipeline_ngram)\n",
    "build_confusion_matrix(svm_pipeline_ngram)\n",
    "build_confusion_matrix(sgd_pipeline_ngram)\n",
    "# build_confusion_matrix(random_forest_ngram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.19      0.30      1169\n",
      "        True       0.58      0.94      0.71      1382\n",
      "\n",
      "    accuracy                           0.59      2551\n",
      "   macro avg       0.65      0.56      0.51      2551\n",
      "weighted avg       0.64      0.59      0.52      2551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.39      0.49      1169\n",
      "        True       0.61      0.81      0.70      1382\n",
      "\n",
      "    accuracy                           0.62      2551\n",
      "   macro avg       0.62      0.60      0.59      2551\n",
      "weighted avg       0.62      0.62      0.60      2551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.47      0.53      1169\n",
      "        True       0.62      0.74      0.68      1382\n",
      "\n",
      "    accuracy                           0.62      2551\n",
      "   macro avg       0.61      0.61      0.60      2551\n",
      "weighted avg       0.62      0.62      0.61      2551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00      1169\n",
      "        True       0.54      1.00      0.70      1382\n",
      "\n",
      "    accuracy                           0.54      2551\n",
      "   macro avg       0.27      0.50      0.35      2551\n",
      "weighted avg       0.29      0.54      0.38      2551\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.48      0.53      1169\n",
      "        True       0.62      0.72      0.67      1382\n",
      "\n",
      "    accuracy                           0.61      2551\n",
      "   macro avg       0.61      0.60      0.60      2551\n",
      "weighted avg       0.61      0.61      0.60      2551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2551,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(DataPrep.test_news['Label'], predicted_nb_ngram))\n",
    "print(classification_report(DataPrep.test_news['Label'], predicted_LogR_ngram))\n",
    "print(classification_report(DataPrep.test_news['Label'], predicted_svm_ngram))\n",
    "print(classification_report(DataPrep.test_news['Label'], predicted_sgd_ngram))\n",
    "print(classification_report(DataPrep.test_news['Label'], predicted_rf_ngram))\n",
    "\n",
    "DataPrep.test_news['Label'].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-search parameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'rf_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "#                'rf_tfidf__use_idf': (True, False),\n",
    "#                'rf_clf__max_depth': (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15)\n",
    "# }\n",
    "\n",
    "# gs_clf = GridSearchCV(random_forest_ngram, parameters, n_jobs=-1)\n",
    "# gs_clf = gs_clf.fit(DataPrep.train_news['Statement'][:10000],DataPrep.train_news['Label'][:10000])\n",
    "\n",
    "# gs_clf.best_score_\n",
    "# gs_clf.best_params_\n",
    "# gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 3.64010558,  2.84611964,  2.72800374,  2.08078723,  8.73642516,\n",
       "         9.75375929,  8.38497081, 10.27888932, 19.04586477, 20.0168014 ,\n",
       "        12.10377817, 18.71813841, 16.76327729, 19.78844309, 18.83204689,\n",
       "        18.78556123, 25.68526502, 30.15381083, 24.46414976, 22.93067317]),\n",
       " 'std_fit_time': array([1.09776665, 1.152043  , 0.96194595, 0.97481516, 3.30175221,\n",
       "        3.58277345, 3.06855521, 3.41177911, 3.45532479, 3.08878969,\n",
       "        3.16687316, 5.42890846, 3.80127887, 7.84198937, 7.36410068,\n",
       "        6.48754612, 5.6573131 , 7.2282266 , 6.73849162, 2.4444665 ]),\n",
       " 'mean_score_time': array([0.41847887, 0.42822547, 0.36529608, 0.35286541, 0.60427089,\n",
       "        0.62873831, 0.38861594, 0.46213613, 0.62139559, 0.51724892,\n",
       "        0.66549001, 0.54295206, 0.79672885, 0.70489445, 0.92112331,\n",
       "        0.6135406 , 1.10463901, 0.6407311 , 0.93957677, 0.50291209]),\n",
       " 'std_score_time': array([0.1440975 , 0.1317633 , 0.19518017, 0.13399353, 0.28222135,\n",
       "        0.30985112, 0.18791452, 0.28251765, 0.244501  , 0.30246786,\n",
       "        0.3231999 , 0.24769541, 0.44834266, 0.39692937, 0.44292027,\n",
       "        0.25355577, 0.32835744, 0.23253963, 0.50634219, 0.07118791]),\n",
       " 'param_LogR_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2),\n",
       "                    (1, 2), (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4),\n",
       "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 5), (1, 5)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_LogR_tfidf__smooth_idf': masked_array(data=[True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_LogR_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 1),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 2),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 3),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 4),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': True,\n",
       "   'LogR_tfidf__use_idf': False},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': True},\n",
       "  {'LogR_tfidf__ngram_range': (1, 5),\n",
       "   'LogR_tfidf__smooth_idf': False,\n",
       "   'LogR_tfidf__use_idf': False}],\n",
       " 'split0_test_score': array([0.6135, 0.617 , 0.6125, 0.617 , 0.619 , 0.617 , 0.6175, 0.617 ,\n",
       "        0.6205, 0.6175, 0.621 , 0.6175, 0.6175, 0.6155, 0.6175, 0.6155,\n",
       "        0.614 , 0.615 , 0.6115, 0.615 ]),\n",
       " 'split1_test_score': array([0.618 , 0.6205, 0.6185, 0.6205, 0.6245, 0.623 , 0.625 , 0.623 ,\n",
       "        0.6245, 0.6165, 0.624 , 0.6165, 0.623 , 0.613 , 0.6205, 0.613 ,\n",
       "        0.622 , 0.6135, 0.619 , 0.6135]),\n",
       " 'split2_test_score': array([0.5945, 0.603 , 0.596 , 0.603 , 0.6025, 0.6015, 0.605 , 0.6015,\n",
       "        0.604 , 0.6045, 0.608 , 0.6045, 0.609 , 0.603 , 0.607 , 0.603 ,\n",
       "        0.6065, 0.601 , 0.609 , 0.601 ]),\n",
       " 'split3_test_score': array([0.599 , 0.608 , 0.5995, 0.608 , 0.6105, 0.605 , 0.6105, 0.605 ,\n",
       "        0.6125, 0.606 , 0.615 , 0.606 , 0.617 , 0.611 , 0.616 , 0.611 ,\n",
       "        0.621 , 0.6115, 0.618 , 0.6115]),\n",
       " 'split4_test_score': array([0.598 , 0.6045, 0.601 , 0.6045, 0.6145, 0.606 , 0.612 , 0.606 ,\n",
       "        0.613 , 0.607 , 0.613 , 0.607 , 0.616 , 0.606 , 0.6185, 0.606 ,\n",
       "        0.6165, 0.6055, 0.618 , 0.6055]),\n",
       " 'mean_test_score': array([0.6046, 0.6106, 0.6055, 0.6106, 0.6142, 0.6105, 0.614 , 0.6105,\n",
       "        0.6149, 0.6103, 0.6162, 0.6103, 0.6165, 0.6097, 0.6159, 0.6097,\n",
       "        0.616 , 0.6093, 0.6151, 0.6093]),\n",
       " 'std_test_score': array([0.00933488, 0.0069383 , 0.00853815, 0.0069383 , 0.00748064,\n",
       "        0.00812404, 0.0067897 , 0.00812404, 0.00709507, 0.00553715,\n",
       "        0.00570614, 0.00553715, 0.00447214, 0.00457821, 0.00468402,\n",
       "        0.00457821, 0.00557674, 0.00525928, 0.00405463, 0.00525928]),\n",
       " 'rank_test_score': array([20,  9, 19,  9,  7, 11,  8, 11,  6, 13,  2, 13,  1, 15,  4, 15,  3,\n",
       "        17,  5, 17])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'LogR_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "               'LogR_tfidf__use_idf': (True, False),\n",
    "               'LogR_tfidf__smooth_idf': (True, False)\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(logR_pipeline_ngram, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(DataPrep.train_news['Statement'][:10000],DataPrep.train_news['Label'][:10000])\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [   nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      " 0.5814 0.5893 0.5821 0.5893 0.5992 0.5984 0.6014 0.5984 0.6047 0.6031\n",
      " 0.6065 0.6031 0.6063 0.607  0.6071 0.607  0.6076 0.6068 0.6082 0.6068]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 1.62760448,  1.39754086,  1.40805645,  1.75635052,  4.33949299,\n",
       "         3.99757333,  3.8840342 ,  4.35341706,  5.33473802,  6.32875338,\n",
       "         5.9024251 ,  6.61488237,  6.56756639,  6.32734327,  8.37713752,\n",
       "         9.20441489, 10.26943183,  9.62884102,  6.47836213,  8.83405824,\n",
       "         2.18224792,  2.43937035,  1.56588473,  1.33014331,  3.87731409,\n",
       "         4.29804592,  4.35308051,  4.00303445,  3.95234308,  3.06792703,\n",
       "         2.90309782,  3.13795657,  5.53303723,  4.49723425,  4.97006869,\n",
       "         4.74228988,  7.09187412,  4.45769601,  6.48444934,  5.76177478]),\n",
       " 'std_fit_time': array([0.477941  , 0.43724116, 0.40876706, 0.29433739, 0.76504005,\n",
       "        0.45332303, 1.32421405, 0.82532787, 1.66749519, 0.93091322,\n",
       "        1.26780489, 1.68256853, 2.47246984, 2.17385286, 2.79525543,\n",
       "        1.95768   , 3.52827912, 2.17414167, 1.44933839, 3.00733221,\n",
       "        0.56532831, 0.13824973, 0.66758601, 0.70828303, 1.82910189,\n",
       "        2.06018411, 1.44017758, 1.00568188, 0.76859424, 0.51631878,\n",
       "        0.40045753, 0.76923284, 0.34274432, 1.47204261, 2.533326  ,\n",
       "        2.38853952, 2.95075287, 1.29275824, 2.80749912, 1.73394531]),\n",
       " 'mean_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3802412 , 0.35873947, 0.25527382, 0.23246784, 0.52374058,\n",
       "        0.41515584, 0.41994591, 0.39164538, 0.28304849, 0.28276901,\n",
       "        0.39857025, 0.33818002, 0.42036901, 0.47042704, 0.40349011,\n",
       "        0.3500217 , 0.91027431, 0.30464029, 0.47143111, 0.39250093]),\n",
       " 'std_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.116873  , 0.12493681, 0.11690109, 0.13540601, 0.26740023,\n",
       "        0.16342976, 0.14523524, 0.0910325 , 0.05391443, 0.04748502,\n",
       "        0.08962135, 0.09263831, 0.26724045, 0.22299683, 0.22549395,\n",
       "        0.14250087, 0.29003402, 0.0110814 , 0.23488905, 0.18412298]),\n",
       " 'param_svm_clf__penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svm_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2),\n",
       "                    (1, 2), (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4),\n",
       "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 5), (1, 5), (1, 1),\n",
       "                    (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2), (1, 2),\n",
       "                    (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4), (1, 4),\n",
       "                    (1, 4), (1, 5), (1, 5), (1, 5), (1, 5)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svm_tfidf__smooth_idf': masked_array(data=[True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False,\n",
       "                    True, True, False, False, True, True, False, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_svm_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l1',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 1),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 2),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 3),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 4),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': True,\n",
       "   'svm_tfidf__use_idf': False},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': True},\n",
       "  {'svm_clf__penalty': 'l2',\n",
       "   'svm_tfidf__ngram_range': (1, 5),\n",
       "   'svm_tfidf__smooth_idf': False,\n",
       "   'svm_tfidf__use_idf': False}],\n",
       " 'split0_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan, 0.5895, 0.5985, 0.5915, 0.5985,\n",
       "        0.6075, 0.6065, 0.611 , 0.6065, 0.611 , 0.607 , 0.6135, 0.607 ,\n",
       "        0.6135, 0.615 , 0.6135, 0.615 , 0.617 , 0.616 , 0.617 , 0.616 ]),\n",
       " 'split1_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan, 0.5925, 0.6025, 0.591 , 0.6025,\n",
       "        0.622 , 0.6215, 0.625 , 0.6215, 0.624 , 0.6195, 0.6265, 0.6195,\n",
       "        0.6215, 0.623 , 0.622 , 0.623 , 0.6195, 0.622 , 0.6215, 0.622 ]),\n",
       " 'split2_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan, 0.571 , 0.576 , 0.5725, 0.576 ,\n",
       "        0.585 , 0.586 , 0.588 , 0.586 , 0.59  , 0.5905, 0.589 , 0.5905,\n",
       "        0.589 , 0.591 , 0.59  , 0.591 , 0.59  , 0.5925, 0.5915, 0.5925]),\n",
       " 'split3_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan, 0.5725, 0.583 , 0.5725, 0.583 ,\n",
       "        0.5855, 0.5835, 0.586 , 0.5835, 0.5905, 0.5945, 0.593 , 0.5945,\n",
       "        0.5975, 0.5995, 0.5975, 0.5995, 0.5995, 0.598 , 0.5975, 0.598 ]),\n",
       " 'split4_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan, 0.5815, 0.5865, 0.583 , 0.5865,\n",
       "        0.596 , 0.5945, 0.597 , 0.5945, 0.608 , 0.604 , 0.6105, 0.604 ,\n",
       "        0.61  , 0.6065, 0.6125, 0.6065, 0.612 , 0.6055, 0.6135, 0.6055]),\n",
       " 'mean_test_score': array([   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "           nan,    nan,    nan,    nan, 0.5814, 0.5893, 0.5821, 0.5893,\n",
       "        0.5992, 0.5984, 0.6014, 0.5984, 0.6047, 0.6031, 0.6065, 0.6031,\n",
       "        0.6063, 0.607 , 0.6071, 0.607 , 0.6076, 0.6068, 0.6082, 0.6068]),\n",
       " 'std_test_score': array([       nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.0086741 , 0.00983158, 0.00839881, 0.00983158, 0.01405916,\n",
       "        0.01407267, 0.01473228, 0.01407267, 0.01296765, 0.01017546,\n",
       "        0.01380942, 0.01017546, 0.01160431, 0.01124722, 0.01163357,\n",
       "        0.01124722, 0.01117766, 0.01094806, 0.01162583, 0.01094806]),\n",
       " 'rank_test_score': array([21, 23, 24, 25, 26, 27, 28, 29, 31, 39, 32, 33, 34, 35, 36, 37, 38,\n",
       "        22, 30, 40, 20, 17, 19, 17, 14, 15, 13, 15, 10, 11,  8, 11,  9,  4,\n",
       "         3,  4,  2,  6,  1,  6])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'svm_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
    "               'svm_tfidf__use_idf': (True, False),\n",
    "               'svm_tfidf__smooth_idf': (True, False),\n",
    "               'svm_clf__penalty': ('l1','l2'),\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(svm_pipeline_ngram, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(DataPrep.train_news['Statement'][:10000],DataPrep.train_news['Label'][:10000])\n",
    "\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "gs_clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running both random forest and logistic regression models again with best parameter found with GridSearch method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.38      0.48      1169\n",
      "        True       0.61      0.82      0.70      1382\n",
      "\n",
      "    accuracy                           0.62      2551\n",
      "   macro avg       0.62      0.60      0.59      2551\n",
      "weighted avg       0.62      0.62      0.60      2551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random_forest_final = Pipeline([\n",
    "#         ('rf_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,3),use_idf=True,smooth_idf=True)),\n",
    "#         ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3,max_depth=10))\n",
    "#         ])\n",
    "    \n",
    "# random_forest_final.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "# predicted_rf_final = random_forest_final.predict(DataPrep.test_news['Statement'])\n",
    "# np.mean(predicted_rf_final == DataPrep.test_news['Label'])\n",
    "# print(metrics.classification_report(DataPrep.test_news['Label'], predicted_rf_final))\n",
    "\n",
    "logR_pipeline_final = Pipeline([\n",
    "        #('LogRCV',countV_ngram),\n",
    "        ('LogR_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,5),use_idf=True,smooth_idf=False)),\n",
    "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
    "        ])\n",
    "\n",
    "logR_pipeline_final.fit(DataPrep.train_news['Statement'],DataPrep.train_news['Label'])\n",
    "predicted_LogR_final = logR_pipeline_final.predict(DataPrep.test_news['Statement'])\n",
    "np.mean(predicted_LogR_final == DataPrep.test_news['Label'])\n",
    "print(sklearn.metrics.classification_report(DataPrep.test_news['Label'], predicted_LogR_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'final_model.sav'\n",
    "pickle.dump(logR_pipeline_ngram,open(model_file,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learing_curve(pipeline,title):\n",
    "    size = 10000\n",
    "    cv = KFold(size, shuffle=True)\n",
    "    \n",
    "    X = DataPrep.train_news[\"Statement\"]\n",
    "    y = DataPrep.train_news[\"Label\"]\n",
    "    \n",
    "    pl = pipeline\n",
    "    pl.fit(X,y)\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(pl, X, y, n_jobs=-1, cv=cv, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
    "       \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "     \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # box-like grid\n",
    "    plt.grid()\n",
    "    \n",
    "    # plot the std deviation as a transparent range at each training set size\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    # plot the average training and test score lines at each training set size\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "    # sizes the window for readability and displays the plot\n",
    "    # shows error from 0 to 1.1\n",
    "    plt.ylim(-.1,1.1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samya\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    }
   ],
   "source": [
    "#below command will plot learing curves for each of the classifiers\n",
    "plot_learing_curve(logR_pipeline_ngram,\"Naive-bayes Classifier\")\n",
    "plot_learing_curve(nb_pipeline_ngram,\"LogisticRegression Classifier\")\n",
    "plot_learing_curve(svm_pipeline_ngram,\"SVM Classifier\")\n",
    "plot_learing_curve(sgd_pipeline_ngram,\"SGD Classifier\")\n",
    "# plot_learing_curve(random_forest_ngram,\"RandomForest Classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PR_curve(classifier):\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(DataPrep.test_news['Label'], classifier)\n",
    "    average_precision = average_precision_score(DataPrep.test_news['Label'], classifier)\n",
    "    \n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "    \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('2-class Random Forest Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "              average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_PR_curve(predicted_LogR_ngram)\n",
    "plot_PR_curve(predicted_rf_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_informative_features(model, vect, clf, text=None, n=50):\n",
    "    # Extract the vectorizer and the classifier from the pipeline\n",
    "    vectorizer = model.named_steps[vect]\n",
    "    classifier = model.named_steps[clf]\n",
    "\n",
    "     # Check to make sure that we can perform this computation\n",
    "    if not hasattr(classifier, 'coef_'):\n",
    "        raise TypeError(\n",
    "            \"Cannot compute most informative features on {}.\".format(\n",
    "                classifier.__class__.__name__\n",
    "            )\n",
    "        )\n",
    "            \n",
    "    if text is not None:\n",
    "        # Compute the coefficients for the text\n",
    "        tvec = model.transform([text]).toarray()\n",
    "    else:\n",
    "        # Otherwise simply use the coefficients\n",
    "        tvec = classifier.coef_\n",
    "\n",
    "    # Zip the feature names with the coefs and sort\n",
    "    coefs = sorted(\n",
    "        zip(tvec[0], vectorizer.get_feature_names()),\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # Get the top n and bottom n coef, name pairs\n",
    "    topn  = zip(coefs[:n], coefs[:-(n+1):-1])\n",
    "\n",
    "    # Create the output string to return\n",
    "    output = []\n",
    "\n",
    "    # If text, add the predicted value to the output.\n",
    "    if text is not None:\n",
    "        output.append(\"\\\"{}\\\"\".format(text))\n",
    "        output.append(\n",
    "            \"Classified as: {}\".format(model.predict([text]))\n",
    "        )\n",
    "        output.append(\"\")\n",
    "\n",
    "    # Create two columns with most negative and most positive features.\n",
    "    for (cp, fnp), (cn, fnn) in topn:\n",
    "        output.append(\n",
    "            \"{:0.4f}{: >15}    {:0.4f}{: >15}\".format(\n",
    "                cp, fnp, cn, fnn\n",
    "            )\n",
    "        )\n",
    "    #return \"\\n\".join(output)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_most_informative_features(logR_pipeline_ngram,vect='LogR_tfidf',clf='LogR_clf')\n",
    "show_most_informative_features(nb_pipeline_ngram,vect='nb_tfidf',clf='nb_clf')\n",
    "show_most_informative_features(svm_pipeline_ngram,vect='svm_tfidf',clf='svm_clf')\n",
    "show_most_informative_features(sgd_pipeline_ngram,vect='sgd_tfidf',clf='sgd_clf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
